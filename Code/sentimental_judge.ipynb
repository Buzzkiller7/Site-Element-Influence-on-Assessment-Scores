{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def map_score_to_5(score):\n",
    "    return round(score * 5, 1)\n",
    "\n",
    "model_name = \"uer/roberta-base-finetuned-jd-binary-chinese\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "data_dir = r\"D:\\Desktop\\gaode\"\n",
    "type_code_path = r\"D:\\Desktop\\gaode\\type_code.csv\"\n",
    "type_code_pd = pd.read_csv(type_code_path)\n",
    "type_results = {}\n",
    "files = [f for f in os.listdir(data_dir) if f.endswith('.json')]\n",
    "\n",
    "for file in tqdm(files, desc=\"Processing files\"):\n",
    "    print(f\"Processing file: {file}\")\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    print(f\"Loaded {len(data)} entries from {file}.\")\n",
    "\n",
    "    # 匹配商铺类型\n",
    "    type_code_str = file.split('_')[0]\n",
    "    if type_code_str.startswith('0'):\n",
    "        type_code_str = type_code_str[1:]\n",
    "    print(f\"Matching type code: {type_code_str}\")\n",
    "    type_name_list = type_code_pd[type_code_pd['NEW_TYPE'] == int(type_code_str)]['Sub Category'].tolist()\n",
    "\n",
    "    if not type_name_list:\n",
    "        print(f\"Error: Type code {type_code_str} not found in type codes.\")\n",
    "        continue\n",
    "\n",
    "    type_name = type_name_list[0]\n",
    "    print(f\"Type name matched: {type_name}\")\n",
    "\n",
    "    # 创建类型结果容器\n",
    "    if type_name not in type_results:\n",
    "        type_results[type_name] = {}\n",
    "\n",
    "    # 处理每个商铺\n",
    "    for entry in data:\n",
    "        shop_name = entry['name']\n",
    "        if 'content' not in entry or not entry['content']:\n",
    "            print(f\"No comments found for shop: {shop_name}\")\n",
    "            continue\n",
    "\n",
    "        # 对商铺的所有评论进行情感分析\n",
    "        comments = entry['content']\n",
    "        sentiment_scores = []\n",
    "        for comment in comments:\n",
    "            result = classifier(comment)\n",
    "            if result:\n",
    "                score = map_score_to_5(result[0]['score'])\n",
    "                sentiment_scores.append(score)\n",
    "\n",
    "        if not sentiment_scores:\n",
    "            print(f\"No valid sentiment scores for shop: {shop_name}\")\n",
    "            continue\n",
    "\n",
    "        # 计算该商铺的平均评分\n",
    "        avg_rating = round(np.mean(sentiment_scores), 1)\n",
    "        print(f\"Shop: {shop_name}, Average Rating: {avg_rating}\")\n",
    "\n",
    "        # 保存到类型结果容器\n",
    "        type_results[type_name][shop_name] = avg_rating\n",
    "\n",
    "# 将结果保存到 CSV 文件\n",
    "for type_name, shops in type_results.items():\n",
    "    output_path = os.path.join(data_dir, f\"{type_name}_ratings.csv\")\n",
    "    df = pd.DataFrame(list(shops.items()), columns=['Shop Name', 'Rating'])\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"All results have been processed and saved.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
